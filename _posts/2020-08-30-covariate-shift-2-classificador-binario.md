---
layout: post
title: Covariate Shift&#58; Classificador Bin√°rio
featured-img: coverclassificador_binario
category: [üáßüá∑, dataset shift]
mathjax: true
summary: Uma t√©cnica para identificar mudan√ßas de distribui√ß√£o a partir de m√©tricas de um classificador bin√°rio.
---

<b>Texto em constru√ß√£o: Pequenas altera√ß√µes de formata√ß√£o.</b>

<p><div align="justify">Este post faz parte de uma s√©rie de postagens que discutem o problema de <i>covariate shift</i>. Assumo que voc√™ j√° conhece a motiva√ß√£o do problema e no que estamos interessados em identificar e corrigir. Se voc√™ ainda n√£o leu o <a href="https://vitaliset.github.io/covariate-shift-0-formulando/">primeiro post</a> dessa s√©rie, sugiro a leitura.</div></p>

<p><div align="justify">Agora, vamos forcar em identificar o <i>covariate shift</i> na distribui√ß√£o conjunta. Desta forma, o problema fica enunciado como: dados $X$ e $Z$ vetores aleat√≥rias e dois conjuntos de observa√ß√µes amostrados de forma independente $\{x_1, x_2, \cdots, x_N \} $ e $\{z_1, z_2, \cdots, z_M \} $, queremos entender se a distribui√ß√£o conjunta √© a mesma, isto √© se $X\sim Z$, estudando apenas as amostras coletadas. No contexto do <i>dataset shift</i>, que estamos particularmente interessados, o vetor aleat√≥rio $X$ indica a distribui√ß√£o das covari√°veis no conjunto de treino e o vetor aleat√≥rio $Z$ nos revela a distribui√ß√£o das vari√°veis explicativas dos dados em produ√ß√£o.</div></p>

<p><div align="justify">Anteriormente, no <a href="https://vitaliset.github.io/covariate-shift-1-qqplot/">segundo post</a> da s√©rie, discutimos uma t√©cnica para encontrar mudan√ßa nas distribui√ß√µes marginais dos vetores aleat√≥rios, o QQ-plot. Sugerimos ainda uma varia√ß√£o num√©rica da t√©cnica visual.</div></p>

<p><div align="justify">Agora, vamos utilizar aprendizado de m√°quina supervisionado para identificar problemas em aprendizado de m√°quina supervisionado.</div></p>

# Entendendo o problema de classifica√ß√£o

<p><div align="justify">O problema de classifica√ß√£o bin√°ria surge naturalmente nesse cen√°rio. Se temos duas amostras de distribui√ß√µes possivelmente diferentes, podemos treinar um modelo que tenta identificar se os dados s√£o da distribui√ß√£o $X$ ou da distribui√ß√£o $Z$. Se as distribui√ß√µes s√£o </div></p>

<p><div align="justify">Se o classificador bin√°rio consegue identificar as diferen√ßas, ent√£o temos uma varia√ß√£o da distribui√ß√£o. Se o classificador n√£o consegue, mantendo uma acur√°cia baixa, ent√£o confiamos que a distribui√ß√£o se manteve parecida.</div></p>

<p><div align="justify">Vamos ilustrar essa t√©cnica nos dados que geraram o desconforto inicial apresentado no final da [postagem anterior](to die by ur side). Aqui fica claro que nem sempre analisar apenas as distribui√ß√µes marginais √© suficiente.</div></p>

<p><div align="justify">Explicitamente temos os vetores aleat√≥rio $X= (X_1,X_2)$ e $Z=(Z_1, Z_2)$ tal que</div></p>

$$
\begin{equation*}
\begin{pmatrix}X_{1}\\
X_{2}
\end{pmatrix} \sim  \mathcal{N}
\begin{pmatrix}
\begin{bmatrix}
0\\
0
\end{bmatrix} ,
\begin{bmatrix}
1 & 0.75 \\
0.75 & 1 
\end{bmatrix}
\end{pmatrix} \textrm{, e }\begin{pmatrix}Z_{1}\\
Z_{2}
\end{pmatrix} \sim  \mathcal{N}
\begin{pmatrix}
\begin{bmatrix}
0\\
0
\end{bmatrix} ,
\begin{bmatrix}
1 & -0.75 \\
-0.75 & 1 
\end{bmatrix}
\end{pmatrix} .
\end{equation*}
$$

```python
def sample(n, t = 1):
    return np.random.multivariate_normal(mean = [0,0], cov = [[1,t*0.75], [t*0.75,1]], size = n).T

X1, X2 = sample(1000)
Z1, Z2 = sample(1000, -1)
```

<center><img src="{{ site.baseurl }}/assets/img/covariate_2_classificador_binario/imagem1.jpg"></center>
<center><b>Figura 1</b>: Dados .</center>

<p><div align="justify">A ideia √© simples, vamos organizar nossos dados criando uma nova coluna que nos diz de o dado √© da distribui√ß√£o $X$ ($s=0$) ou da distribui√ß√£o $Z$ ($s=1$).</div></p>

```python
df = pd.DataFrame({'variavel_1':np.concatenate([X1,Z1]), 'variavel_2':np.concatenate([X2,Z2]), 's':[0]*X1.shape[0]+[1]*Z1.shape[0]})

X_miss = np.asarray(df.drop(['s'],axis=1))
S_miss = np.asarray(df['s'])
```

| vari√°vel 1 | vari√°vel 2 |   y   |  s   |
| :--------: | :--------: | :---: | :--: |
|  0.178105  |  0.651739  | $y_1$ |  0   |
|  0.464192  | -0.461877  | $y_2$ |  0   |
|   1.0948   |  0.823703  | $y_3$ |  0   |
|    ...     |    ...     |  ...  | ...  |
|  0.393783  | -0.681826  |   ?   |  1   |
|  0.623834  | -0.344885  |   ?   |  1   |
| -0.800357  |  0.444416  |   ?   |  1   |

<p><div align="justify">Aqui, j√° fazendo um panorama com a realidade em que estamos aplicando esse modelo, coloquei uma coluna para a vari√°vel target $y$ que seria a vari√°vel alvo do nosso problema inicial. N√£o vamos usar ela em nenhum momento na identifica√ß√£o do <i>covariate shift</i>, o que √© esperado j√° que n√£o temos os targets dos dados novos encontrados na produ√ß√£o.</div></p>

<p><div align="justify">Com essa estrutura constru√≠da, a ideia √© simples. Criamos um classificador que utiliza as vari√°veis 1 e 2 para prever $s$. Se o seu resultado em um conjunto de teste √© ruim, ent√£o os dados de $X$ e $Z$ s√£o indistingu√≠veis e conclu√≠mos que $X\sim Z$. Agora, se o nosso classificador tem boas m√©tricas, ent√£o quer dizer que as distribui√ß√µes diferem.</div></p>

# Construindo e avaliando o classificador bin√°rio

<p><div align="justify">Primeiro, separamos nossos dados em 2 conjuntos. Um para treino e outro para teste.</div></p>

```python
X_miss_train, X_miss_test, S_miss_train, S_miss_test = train_test_split(X_miss, S_miss, test_size = 0.8)
```

<p><div align="justify">Agora podemos utilizar o classificador bin√°rio qualquer. Como estou come√ßando a me apaixonar pelo Vapnik, vou utilizar uma Support Vector Machine. Os hiper-par√¢metros "default" das SVM costumam fazer um bom trabalho, mas em um mundo ideal, podemos fazer uma pequena otimiza√ß√£o dos hiper-par√¢metros maximizando a m√©trica <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html"><code>roc_auc_score</code></a>. </div></p>

```python
param = {'C': np.geomspace(0.01,100,13), 'gamma': ['scale']+list(np.geomspace(0.1,100,10)), 'kernel' = ['rbf']}
grid_search = GridSearchCV(SVC(probability=True), param, cv = 5, scoring= ['roc_auc','accuracy'], refit = 'roc_auc', return_train_score=True)
grid_search.fit(X_miss_train, S_miss_train)
```

<p><div align="justify">Em seguida, utilizamos o modelo encontrado em todos os dados e podemos avaliar seu desempenho. </div></p>

```python
svm = SVC(probability=True, **grid_search.best_params_)
svm.fit(X_miss_train,S_miss_train)

print('acuracia: ',accuracy_score(S_miss_test,svm.predict(X_miss_test)))
print('roc_auc: ',roc_auc_score(S_miss_test,svm.predict(X_miss_test)))
print('phi coeficiente: ',matthews_corrcoef(S_miss_test,svm.predict(X_miss_test)))
```

```
acuracia:  0.72625
roc_auc:  0.7268930344332967
phi coeficiente:  0.4827618287310226
```

<p><div align="justify">N√£o temos uma acur√°cia estado da arte, mas claramente nosso modelo identificou um padr√£o e consegue discriminar dados como sendo de uma distribui√ß√£o ou de outra.</div></p>

<p><div align="justify">$\oint$ <i>¬†Uma m√©trica n√£o t√£o cl√°ssica, mas muito √∫til √© o <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html">coeficiente de correla√ß√£o de Matthews</a>. Inspirado no coeficiente de correla√ß√£o de Pearson, queremos entender correla√ß√£o para atributos categ√≥ricos. Isso deu origem ao coeficiente phi de Pearson, a ideia dele √© generalizar o coeficiente de correla√ß√£o entre a nossa previs√£o e os valores reais da target bin√°ria. √â uma forma num√©rica de avaliar a matriz de confus√£o. Seu c√°lculo √© feito como</i></div></p>

$$
\begin{equation*}
\textrm{MCC} = \frac{T_p \, T_n - F_p \, F_n}{\sqrt{(T_p+F_p)(T_p+F_n)(T_n+F_p)(T_n+F_n)}},
\end{equation*}
$$

<p><div align="justify"><i>em que $T_p$¬†√© o n√∫mero de verdadedeiros positivos, $T_n$, a quantidade de verdadeiros negativos, $F_p$¬†o n√∫mero de falsos positivos e $F_n$¬†o n√∫mero de falsos negativos. Apesar de parecer um pouco confuso, analisando o numerador vemos que estamos multiplicando os valores corretamente classificados e subtraindo a multiplica√ß√£o dos incorretamente classificados. O denominador serve como uma normaliza√ß√£o deixando o resultado entre $-1$ e $1$, em que $1$¬†significa uma previs√£o perfeita, $0$¬†uma previs√£o aleat√≥ria e $-1$¬†uma previs√£o trocada.</i></div></p>

<p><div align="justify">No nosso caso ilustrativo em duas dimens√µes, podemos fazer as curvas de n√≠vel do <code>predict_proba</code> do SVM e visualizar que ele entendeu as regi√µes mais prov√°veis de cada uma das distribui√ß√µes.</div></p>

<center><img src="{{ site.baseurl }}/assets/img/covariate_2_classificador_binario/imagem2.jpg"></center>
<center><b>Figura 2</b>: Dados .</center>

<p><div align="justify">$\oint$ <i>O SVM n√£o nos da naturalmente o <code>predict_proba</code>, precisamos passar <code>probability=True</code> na sua inicializa√ß√£o. O <code>sklearn</code> aplica a <a href="https://www.cs.colorado.edu/~mozer/Teaching/syllabi/6622/papers/Platt1999.pdf">abordagem de Platt</a> utilizando uma <a href="https://scikit-learn.org/stable/modules/svm.html#scores-probabilities">regress√£o log√≠stica no score do SVM</a>. Essa t√©cnica pode ser utilizada com classificadores quaisquer, para melhorar a <a href="https://scikit-learn.org/stable/modules/calibration.html#calibration">calibra√ß√£o de probabilidade</a>. Inclusive √© uma <a href="https://gdmarmerola.github.io/probability-calibration/">t√©cnica √∫til para ensembles de √°rvores</a>.</i></div></p>

# Entendendo a mudan√ßa na distribui√ß√£o a partir do classificador

<p><div align="justify">Agora precisamos avaliar se as distribui√ß√µes s√£o diferentes ou n√£o. Podemos analisar um histograma dos <code>predict_proba</code> aplicado nas duas amostras separadamente como vemos na Figura 3. Claramente, nosso SVM identifica regi√µes em que a chance de ser de uma das distribui√ß√µes √© maior do que ser de outra. Ele nos dar tanta certeza √© um indicativo de que ele consegue distinguir bem.</div></p>

<center><img src="{{ site.baseurl }}/assets/img/covariate_2_classificador_binario/imagem3.jpg"></center>
<center><b>Figura 3</b>: Dados .</center>

<p><div align="justify">Supondo que confiamos na medida de probabilidade que ele nos d√°. Uma m√©trica um pouco arbitr√°ria √© olhar qual a porcentagem dos dados est√° na regi√£o entre $[0, x) \cup (0.5+x,1]$ para $0\leq x\lt 0.5$. Por exemplo, podemos olhar a propor√ß√£o de exemplos com <code>predict_proba</code> de $0$ a $25\%$ ou de $75\%$ a $100\%$. Estes s√£o os dados que o classificador julga como "f√°ceis de classificar" por estarem em regi√µes dominadas por alguma das classes.</div></p>

```python
x = 0.25
((svm.predict_proba(X_miss)[:,0]<0.5-x) | (svm.predict_proba(X_miss)[:,0]>0.5+x)).sum()/X_miss.shape[0]
```

```
0.4605
```

<p><div align="justify">Quase metade dos dados est√£o nas regi√µes "f√°ceis" de acordo com essa an√°lise de probabilidade. Claro que isso n√£o √© perfeito pela exist√™ncia de outliers, mas √© um indicativo claro de que existem regi√µes do espa√ßo de atributos favorecidas por uma das distribui√ß√µes e regi√µes do espa√ßo favorecidas pela outra distribui√ß√£o. Fixado $x$, podemos escolher um valor $\varepsilon\in(0,1]$ tal que: se a propor√ß√£o de dados nas regi√µes "f√°ceis" for maior que $\varepsilon$ ent√£o temos um alerta que h√° uma mudan√ßa na distribui√ß√£o.</div></p>

<p><div align="justify">Podemos tentar criar tamb√©m thresholds de acur√°cia ou do coeficiente phi que indicam que h√° uma mudan√ßa na distribui√ß√£o ou n√£o. Isso n√£o √© necessariamente claro tamb√©m e podemos gerar monitorar com rigor demais ou sendo muito brandos.</div></p>

<p><div align="justify">Como discutido no post anterior, esses tresholds universais n√£o existem. O que vale √© analisar nos seus dados hist√≥ricos casos de <i>covariate shift</i> que voc√™ sabe que aconteceram e analisar se existiria um $\varepsilon$ que teria funcionado neles.</div></p>

# Caso sem mudan√ßa

<p><div align="justify">Vale estudar como essa metodologia se comportaria em casos em que n√£o h√° mudan√ßa na distribui√ß√£o. Por exemplo, se ambas as distribui√ß√µes fossem geradas pela mesma normal multivariada dada por</div></p>

$$
\begin{equation*}
\begin{pmatrix}X_{1}\\
X_{2}
\end{pmatrix},
\begin{pmatrix}Z_{1}\\
Z_{2}
\end{pmatrix} \sim  \mathcal{N}
\begin{pmatrix}
\begin{bmatrix}
0\\
0
\end{bmatrix} ,
\begin{bmatrix}
1 & 0.75 \\
0.75 & 1 
\end{bmatrix}
\end{pmatrix}.
\end{equation*}
$$

```python
X1, X2 = sample(1000)
Z1, Z2 = sample(1000)
```

<p><div align="justify">Fazendo exatamente os mesmos procedimentos que anteriormente, temos agora curvas de n√≠vel muito mais confusas como vemos na Figura 4. O classificador tenta se adaptar um pouco √†s particularidades das amostras, mas n√£o se atreve a dar probabilidades altas para nenhuma das regi√µes justamente porque nenhuma das regi√µes √© privilegiada por uma das distribui√ß√µes neste caso.</div></p>

<center><img src="{{ site.baseurl }}/assets/img/covariate_2_classificador_binario/imagem4.jpg"></center>
<center><b>Figura 4</b>: Dados .</center>

<p><div align="justify">Isso fica ainda mais claro quando olhamos para as m√©tricas de classifica√ß√£o neste caso. Fica claro que as distribui√ß√µes s√£o indistingu√≠veis nesse caso, como esperado.</div></p>

```
acuracia:  0.511875
roc_auc:  0.5115329746824565
phi coeficiente:  0.023459774068708163
```

<p><div align="justify">A an√°lise da distribui√ß√£o dos <code>predict_proba</code> tamb√©m conversa com o que esper√°vamos. Agora, o modelo √© muito mais conservador, colocando as probabilidades pr√≥ximas de $0.5$ como vemos na Figura 5.  </div></p>

<center><img src="{{ site.baseurl }}/assets/img/covariate_2_classificador_binario/imagem5.jpg"></center>
<center><b>Figura 5</b>: Dados .</center>

<p><div align="justify">Neste caso, os <code>predict_proba</code> est√£o concentrados entre $0.4$ e $0.6$, como esperado. O modelo √© conservador e n√£o encontra regi√µes f√°ceis de classifica√ß√£o.</div></p>

```python
x = 0.1
((svm.predict_proba(X_miss)[:,0]<0.5-x) | (svm.predict_proba(X_miss)[:,0]>0.5+x)).sum()/X_miss.shape[0]
```

```
0.0
```

# Pontos de aten√ß√£o e considera√ß√µes finais

<p><div align="justify">Assim como a maioria das t√©cnicas de monitoramento, n√£o √© necessariamente claro identificar se h√° ou n√£o o <i>covariate shift</i> categoricamente. A cria√ß√£o de thresholds para alertas √© nebulosa. A ideia √© sempre utilizar v√°rias formas de avaliar, gerando relat√≥rios que precisam ser olhados de forma cr√≠tica.</div></p>

<p><div align="justify">Em muitos casos, toda essa an√°lise com otimiza√ß√£o de hiper-par√¢metros e utilizando modelos custosos como o SVM pode ser invi√°vel. N√£o precisamos ter um classificador bin√°rio estado da arte, ele s√≥ precisa ser bom o suficiente para conseguir aprender a identificar as regi√µes de cada uma das amostras (se existir) dando probabilidades adequadas. Logo, fique a vontade para escolher o classificador que voc√™ mais gostar, com o cuidado na hora das an√°lises do <code>predict_proba</code>. Como comentei anteriormente, os par√¢metros default das SVM costumam ser razo√°veis e voc√™ pode sempre pegar algumas sub-amostras dos dados para fazer essas an√°lises.</div></p>

<p><div align="justify">√â razo√°vel se preocupar tamb√©m com o balanceamento entre o tamanho dos dados de treino ($s=0$) e dados de produ√ß√£o ($s=1$) para ser razo√°vel analisar acur√°cia e m√©tricas simples. Novamente, lembrando que esse classificador n√£o precisa ser perfeito, um <i>undersample</i> da classe dominante me parece suficiente.</div></p>

<p><div align="justify">Essa t√©cnica incorporada em linhas de produ√ß√£o robustas pode ser uma forma inteligente de identifica√ß√£o de varia√ß√£o das covari√°veis de treino e produ√ß√£o. No pr√≥ximo post utilizaremos o princ√≠pio da minimiza√ß√£o do erro emp√≠rico de Vapnik para discutir porque o <i>covariate shift</i> se torna um problema. Essa narrativa nos indicar√° uma maneira elegante de amenizar os problemas causados pelo <i>covariate shift</i> quando o retreino com dados mais parecidos com os da produ√ß√£o n√£o √© poss√≠vel.</div></p>