---
layout: post
title: Covariate Shift&#58; Formulando o problema
featured-img: covariate_0_formulando
category: [üáßüá∑, dataset shift]
mathjax: true
summary: Apresentando o cen√°rio do dataset shift com um caso ilustrativo.
---

<p><div align="justify">Um dos objetivos do aprendizado supervisionado √© tentar reconhecer padr√µes entre vari√°veis explicativas e uma vari√°vel alvo. Matematicamente, temos um vetor aleat√≥rio $V = (X_1, X_2, \cdots, X_n, Y)$ e supomos que existe uma rela√ß√£o entre as vari√°veis explicativas $X_i$ e a vari√°vel alvo $Y$ do tipo</div></p>

$$
\begin{equation*}
Y \sim f(X_1, X_2,\cdots, X_n) + \varepsilon,
\end{equation*}
$$

<p><div align="justify">onde $f:\mathbb{R}^n\to \mathbb{R}$ √© uma fun√ß√£o qualquer e $\varepsilon$ √© uma vari√°vel aleat√≥ria com m√©dia $0$ chamada de ru√≠do (que possivelmente pode mudar dependendo dos valores de $X_i$ tamb√©m). O objetivo do paradigma de aprendizado supervisionado √© estimar a fun√ß√£o $f$ com observa√ß√µes anteriores (uma amostra do vetor aleat√≥rio $V$).</div></p>

<p><div align="justify">Em geral, quando fazemos valida√ß√µes <i>hold-out</i> e <i>k-fold</i>, esperamos que o desempenho da nossa fun√ß√£o estimada continue sendo o mesmo que no conjunto de valida√ß√£o quando o modelo se deparar com dados novos. O problema de aprendizado de m√°quina em <b>ambientes n√£o-estacion√°rios</b> traz novos desafios ao nosso trabalho:  e se houver um <i><b>Dataset Shift</b></i>, isto √©, e se a distribui√ß√£o do vetor aleat√≥rio $V$ for diferente nos dados que ainda n√£o conhecemos? √â razo√°vel esperar que o modelo mantenha o desempenho obtido na valida√ß√£o?</div></p>

<p><div align="justify">Dentro desse contexto h√° pelo menos duas varia√ß√µes cl√°ssicas. A primeira √© o <b><i>Concept Shift</i></b>, que ocorre quando a fun√ß√£o $f$ que relaciona as vari√°veis $X_i$ e $Y$ muda. Um problema aparentemente mais sutil, mas igualmente apavorante √© o caso em que a rela√ß√£o entre as vari√°veis explicativas e a vari√°vel alvo √© conservada, mas a distribui√ß√£o das vari√°veis $X_i$ nos novos exemplos √© diferente da distribui√ß√£o das vari√°veis $X_i$ nos dados de treinamento. Esse √© o <i><b>Covariate Shift</b></i>, situa√ß√£o que vamos aprender a identificar nesta s√©rie de posts e dar uma poss√≠vel abordagem de solu√ß√£o.</div></p>

<p><div align="justify">Antes, para esclarecer as ideias com uma situa√ß√£o pr√°tica, vamos construir artificialmente um cen√°rio que apresenta <i>Covariate Shift</i> e analisar o problema que surge se isso n√£o √© identificado e tratado de maneira adequada.</div></p>

# Exemplo de dataset shift entre dados de treino e dados de produ√ß√£o

<p><div align="justify">Sejam $X$ uma vari√°vel aleat√≥ria tal que $X\sim \mathcal{N}(0,1)$, $f:\mathbb{R}\to\mathbb{R}$  uma fun√ß√£o da forma $f(t) = \cos(2\pi t)$ e $\varepsilon$  o ru√≠do modelado como $\varepsilon \sim \mathcal{N}(0,0.25)$. Construiremos um conjunto de dados gerados por esse experimento aleat√≥rio.</div></p>

```python
def f(X):
    return np.cos(2*np.pi*X) 

def f_ruido(X):
    '''
    Retorna uma amostra da v.a. Y, fixada uma amostra do v.a. X,
    entregue como par√¢metro.
    '''
    return f(X) + np.random.normal(0, 0.5, size = X.shape[0])
    
def sample(n, mean = 0):
    '''
    Retorna uma amostra do vetor aleat√≥rio (X,Y).
    O par√¢metro n √© o tamanho da amostra desejada, e o
    valor mean √© a m√©dia da normal, distribui√ß√£o de X.
    '''
    X = np.random.normal(mean, 1, size=n)
    Y = f_ruido(X)
    return X.reshape(-1, 1), Y.reshape(-1, 1)
```

<p><div align="justify">Neste exemplo, faremos este experimento $100$ vezes, criando nossos dados com a m√©dia de $X$ em $0$ como comentado anteriormente.</div></p>

```python
X_past, Y_past = sample(100)
```

<p><div align="justify">Apesar do ru√≠do ser da ordem de grandeza $f$, √© poss√≠vel visualizar o padr√£o da fun√ß√£o que guia a gera√ß√£o dos dados, como observamos na Figura 1. Estamos interessados em fazer previs√µes: dadas novas observa√ß√µes de $x$, queremos estimar os respectivos valores para $y$.</div></p>

<p><center><img src="{{ site.baseurl }}/assets/img/covariate_0_formulando_post/imagem1.png"></center>
<center><b>Figura 1</b>: Os pontos azuis s√£o nossas observa√ß√µes e em preto temos a curva que gerou os dados.</center></p>

<p><div align="justify">Usaremos um modelo simples para fazer a regress√£o, a √Årvore de Decis√£o. Com um <i>GridSearch</i>, escolhemos o melhor valor para o m√≠nimo de exemplos por folha (par√¢metro de regulariza√ß√£o, evitando <i>overfit</i>). Olhando, ainda, a valida√ß√£o cruzada para um <i>k-fold</i> com 5 pastas, estimamos o valor de $R^2$ se utiliz√°ssemos a √°rvore em dados nunca vistos.</div></p>

```python
dtr = DecisionTreeRegressor()
param = {'min_samples_leaf': np.arange(1,10,1)}
grid_search = GridSearchCV(dtr, param, cv = 5, scoring= 'r2', return_train_score=True)
grid_search.fit(X_past, Y_past)
```

<p><div align="justify">Obtemos um $R^2=0.486$, demonstrando h√° um aprendizado dos padr√µes dos dados (apesar de ser um modelo simples e termos poucos exemplos). Treinando novamente a √°rvore em todos os exemplos, podemos ver na Figura 2 que ele se aproxima da fun√ß√£o original $f$.</div></p>

```python
dtr = DecisionTreeRegressor(min_samples_leaf = grid_search.best_params_['min_samples_leaf'])
dtr.fit(X_past,Y_past)
```

<p><center><img src="{{ site.baseurl }}/assets/img/covariate_0_formulando_post/imagem2.png"></center>
<center><b>Figura 2</b>: Adicionamos, em vermelho, a fun√ß√£o estimada pelo modelo que tenta se aproximar da geradora, em preto.</center></p>

<p><div align="justify">Graficamente, vemos que o modelo faz um trabalho razo√°vel ao redor do $0$, e perde a qualidade nas bordas, onde h√° menos exemplos de treinamento.</div></p>

<p><div align="justify">Imaginemos agora que o cen√°rio mudou: apesar da rela√ß√£o entre $X$ e $Y$ continuar sendo a mesma, por algum motivo, a vari√°vel $X$ n√£o √© tem mais distribui√ß√£o dada por $X\sim \mathcal{N}(0,1)$. Nesta varia√ß√£o, ela √© dada por $X\sim \mathcal{N}(2,1)$, ou seja, temos uma transla√ß√£o da distribui√ß√£o.</div></p>

```python
X_new, Y_new = sample(100, mean = 2)
```

<p><div align="justify">Os dados agora est√£o distribu√≠dos mais a direita, como podemos visualizar na Figura 3.</div></p>

<p><center><img src="{{ site.baseurl }}/assets/img/covariate_0_formulando_post/imagem3.png"></center>
<center><b>Figura 3</b>: Histograma comparando a distribui√ß√£o das duas amostras que temos. Em azul a feita quando X tinha m√©dia 0 e em laranja a nova, com m√©dia 2.</center></p>

<p><div align="justify">√â razo√°vel esperar que o desempenho do nosso modelo continue o mesmo? Podemos ver na Figura 4 que n√£o.</div></p>

<p><center><img src="{{ site.baseurl }}/assets/img/covariate_0_formulando_post/imagem4.png"></center>
<center><b>Figura 4</b>: Agora, para os novos dados em laranja, extendemos o dom√≠nio do nosso modelo e vemos que ele n√£o faz um bom trabalho tentando aproximar a curva geradora.</center></p>

<p><div align="justify">Como esperado, a qualidade do modelo cai para um $R^2$ de $-0.283$ nos dados novos. Isto lembrando que a rela√ß√£o entre $X$ e $Y$ n√£o mudou, apenas a distribui√ß√£o de $X$.</div></p>

# Identificando <i>Covariate Shfit</i>

<p><div align="justify">Dada a motiva√ß√£o inicial, temos um desafio resumido no seguinte enunciado:</div></p>

<p><div align="justify">Seja $X$ e $Z$ vari√°veis (ou vetores) aleat√≥rias. Suponha que amostre $X$ de forma independente $N\in\mathbb{N}^*$ vezes e tamb√©m $Z$ seja amostrada tamb√©m de forma independente $M\in \mathbb{N}^*$ vezes ficando com as amostras $\{x_1, x_2, \cdots, x_N \} $ e $\{z_1, z_2, \cdots, z_M \} $. Como saber se $X\sim Z$ olhando apenas para as duas amostras? No contexto espec√≠fico do <i>Covariate Shift</i>, vamos estar comparando as amostras das covari√°veis no treino e depois em produ√ß√£o.</div></p>

<p><div align="justify">No geral, o monitoramento da distribui√ß√£o das covari√°veis precisa ser simples. M√©todos b√°sicos s√£o escolhidos no lugar de t√©cnicas complexas privilegiando efici√™ncia computacional. Al√©m disso, a an√°lise costuma ser feita olhando covari√°vel por covari√°vel, identificando mudan√ßas nessas distribui√ß√µes marginais. Entre os m√©todos cl√°ssicos univariados, se destacam:</div></p>

- <p><div align="justify">Compara√ß√£o de estat√≠sticas: m√©dias, vari√¢ncias e alguns quantis amostrais;</div></p>

- <p><div align="justify">Compara√ß√£o de frequ√™ncias para distribui√ß√µes discretas e dados categ√≥ricos;</div></p>

- <p><div align="justify">Teste de Kolmogorov-Smirnov;</div></p>

- <p><div align="justify">Diverg√™ncia de Kullback-leibler.</div></p>

<p><div align="justify">Muitas vezes esse monitoramente √© feito aliado √† an√°lise da distribui√ß√£o da sa√≠da do modelo. Se antes o nosso modelo indicava que $10%$ dos dados eram de uma classe e agora ele diz que $20%$ s√£o daquela classe, temos um bom indicativo de que a distribui√ß√£o de entrada mudou.</div></p>

<p><div align="justify">Nesta s√©rie de postagens pretendo apresentar alguns m√©todos um pouco mais alternativos para identificar o <i>Covariate Shift</i>. Em seguida, vamos entender porque ele ocorre sob a luz da minimiza√ß√£o do risco emp√≠rico de Vapnik. Derivaremos uma maneira muito elegante de trat√°-lo a partir de uma t√©cnica que utilizamos para identifica√ß√£o do <i>dataset shift</i>.</div></p>

