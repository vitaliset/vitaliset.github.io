---
layout: post
title: Uma utiliza√ß√£o cr√≠tica do Boruta
featured-img: boruta
category: [üáßüá∑, feature selection]
mathjax: true
summary: Um passo a passo da utiliza√ß√£o do Boruta, discutindo a motiva√ß√£o da constru√ß√£o e debatendo varia√ß√µes √∫teis do algoritmo.
---

<p><div align="justify">Se fixarmos o poder preditivo no conjunto de desenvolvimento, um modelo com menos atributos tende a ter menor propens√£o de abusar de ru√≠dos e rela√ß√µes esp√∫rias do seu conjunto de treinamento, o que pode lev√°-lo a ganhos de performance fora do laborat√≥rio. Uma sele√ß√£o bem feita de vari√°veis √©, portanto, uma ferramenta <em>data-centric</em> importante na modelagem de problemas de aprendizado de m√°quina supervisionado.</div></p>

<p><div align="justify"><i>$\oint$ Para ilustrar a afirma√ß√£o anterior, temos, como exemplo, que a <a href="https://youtu.be/Dc0sr0kdBVI">dimens√£o-VC</a> (medida de complexidade de uma fam√≠lia de hip√≥teses) de um perceptron (classificador linear) √© $d+1$, em que $d$ √© o n√∫mero de vari√°veis utilizadas no modelo [<a href="#bibliography">1</a>]. Um modelo com dimens√£o-VC maior significa que voc√™ precisa de um volume de dados maior para garantir que sua performance, medida no treinamento, seja semelhante √† performance real. Na pr√°tica, isso significa que quanto maior a dimens√£o-VC, maior a chance de overfitting. Consequentemente, nesse exemplo, se temos dois perceptrons com performances semelhantes no treino, com a diferen√ßa de que um tem mais vari√°veis que o outro, o que tem mais vari√°veis tem maior chance de apresentar overfitting [<a href="#bibliography">1</a>].</i></div></p>

<p><div align="justify">Entretanto, a sele√ß√£o de vari√°veis n√£o √© vista com o cuidado devido na maioria dos cursos de Aprendizado de M√°quina. S√£o apresentados poucos m√©todos e de maneira superficial. Os poucos lugares que discutem o tema, no geral, focam ainda em t√©cnicas que s√£o pouco escal√°veis com o aumento de vari√°veis e, por isso, s√£o pouco pratic√°veis na maioria das aplica√ß√µes do mercado (como as estrat√©gias gulosas de <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html"><code>sklearn.feature_selection.SequentialFeatureSelector</code></a>).</div></p>

<p><div align="justify">No <a href="https://br.linkedin.com/showcase/serasa-experian-datalab">DataLab da Serasa Experian</a>, sele√ß√£o de vari√°veis se torna extremamente relevante pela natureza dos problemas que trabalhamos. Na grande maioria dos casos temos algumas milhares de vari√°veis dispon√≠veis no bureau de dados da Serasa e n√£o √© f√°cil identificar de antem√£o quais ser√£o as features que nos dar√£o mais ganhos. √â necess√°rio aplicar t√©cnicas que s√£o robustas √† grandeza do n√∫mero de vari√°veis que temos ao mesmo tempo que garantam uma sele√ß√£o que fa√ßa sentido.</div></p>

<p><div align="justify">Neste post, iremos motivar a constru√ß√£o do Boruta [<a href="#bibliography">2</a>], uma das t√©cnicas mais utilizadas pelos cientistas do <a href="https://br.linkedin.com/showcase/serasa-experian-datalab">DataLab</a> na sele√ß√£o de features, com algumas dicas de uso pr√°tico. Ilustraremos ainda o uso da fun√ß√£o <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a>, do ambiente <a href="https://github.com/scikit-learn-contrib/scikit-learn-contrib/blob/master/README.md">scikit-learn-contrib</a> (ou seja, compat√≠vel com bibliotecas que seguem o <a href="https://scikit-learn.org/stable/developers/develop.html">padr√£o de c√≥digo do scikit-learn</a>).</div></p>

___

<p><div align="justify">Para ilustrar o problema de sele√ß√£o de features, utilizaremos o <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html"><code>sklearn.datasets.make_classification</code></a> para criar um problema gen√©rico de classifica√ß√£o em que podemos definir, como um par√¢metro da fun√ß√£o, o n√∫mero de vari√°veis √∫teis para o problema de previs√£o.</div></p>

```python
from sklearn.datasets import make_classification

N_FEATURES = 20

X, y = \
make_classification(n_samples=1000,
                    n_features=N_FEATURES,
                    n_informative=2,
                    n_redundant=2,
                    n_classes=2,
                    flip_y=0.1,
                    shuffle=False,
                    random_state=42)

X = pd.DataFrame(X, columns=[f'column_{i+1}' for i in range(N_FEATURES)])

X.head()
```

<p><center><img src="{{ site.baseurl }}/assets/img/boruta/output_2_0.png"></center></p>

<p><div align="justify">Como estamos escolhendo 2 features informativas e 2 features redundantes, temos que as 4 features mais importantes s√£o as colunas: <code>column_1</code>, <code>column_2</code>, <code>column_3</code> e <code>column_4</code>.</div></p>

# Motivando a constru√ß√£o do Boruta

## Medindo a import√¢ncia de uma vari√°vel

<p><div align="justify">Uma das t√©cnicas mais comuns para selecionar as vari√°veis √© aproveitar-se de modelos que, de alguma forma, selecionam-nas no pr√≥prio processo de treinamento. √Årvores e, consequentemente, comit√™s de √°rvores s√£o, talvez, o melhor exemplo disso: pela <a href="https://www.edureka.co/community/46109/what-is-greedy-approach-in-decision-tree-algorithm">estrat√©gia gulosa de fazer a melhor quebra poss√≠vel naquele instante</a> (de acordo com algum crit√©rio de melhor, usualmente relacionado √† pureza das folhas criadas, no caso de classifica√ß√£o), estamos sempre escolhendo vari√°veis relevantes. Vari√°veis pouco discriminativas s√£o utilizadas muito menos que as vari√°veis que de fato ajudam a fazer a previs√£o [<a href="#bibliography">3</a>].</div></p>

<p><div align="justify">Esse processo, naturalmente deriva medidas de import√¢ncia para as vari√°veis como: o n√∫mero de vezes que ela √© utilizada (esse √© o modo default do atributo <code>.feature_importance_</code> dos ensembles do LGBM, como o <a href="https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html"><code>lightgbm.LGBMClassifier</code></a>) ou uma pondera√ß√£o do ganho de informa√ß√£o durante a escolha das quebras das features (essa √© a forma default dos ensembles de √°rvores do sklearn, como o <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"><code>sklearn.ensemble.RandomForestClassifier</code></a>, o <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"><code>sklearn.ensemble.ExtraTreesClassifier</code></a>, e o <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.HistGradientBoostingClassifier.html"><code>sklearn.ensemble.HistGradientBoostingClassifier</code></a>, al√©m de tamb√©m virar o atributo do LGBM quando definimos o <code>importance_type=&#39;gain&#39;</code>).</div></p>

<p><div align="justify">Com alguma dessas medidas naturais de import√¢ncia, √© razo√°vel ordenar nossas vari√°veis da mais importante para a menos importante.</div></p>

```python
from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(random_state=42).fit(X, y)

df_imp = \
(pd.DataFrame(list(zip(X.columns, rfc.feature_importances_)),
              columns=['feature_name', 'feature_importance'])
 .sort_values(by='feature_importance', ascending=False)
 .reset_index(drop=True)
)

df_imp
```

<p><center><img src="{{ site.baseurl }}/assets/img/boruta/output_5_0.png"></center></p>

<p><div align="justify"><i>$\oint$ Existem algumas outras formas de metrificar a import√¢ncia de uma vari√°vel como, por exemplo, utilizando suas contribui√ß√µes de <a href="https://towardsdatascience.com/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30">valores SHAP</a>. Tendo em vista que o <a href="https://github.com/slundberg/shap"><code>shap.Explainer(model).shap_values(X)</code></a> nos retorna uma medida de quanto aquela vari√°vel agregou na previs√£o, pegar a sua m√©dia entre todos os exemplos nos d√° uma forma de ver o qu√£o √∫til ela foi para discriminar os exemplos como um todo. Para os valores n√£o se cancelarem (imagine uma vari√°vel que para determinados valores joga a previs√£o para cima e em outros valores joga a previs√£o para baixo), tomamos o m√≥dulo antes de fazer a m√©dia. Repare que a ordem das import√¢ncias dada pelo SHAP pode ser diferente da ordem de import√¢ncias dada pelo atributo de <code>.feature_importance_</code> usual do estimador, como √© o caso do nosso exemplo.</i></div></p>

```python
explainer = shap.TreeExplainer(rfc)
shap_vals = explainer.shap_values(X)

df_imp_shap = \
(pd.DataFrame(list(zip(X.columns, np.abs(shap_vals[0]).mean(axis=0))),
              columns=['feature_name', 'shap_importance'])
 .sort_values(by='shap_importance', ascending=False)
 .reset_index(drop=True)
)

df_imp_shap
```

<p><center><img src="{{ site.baseurl }}/assets/img/boruta/output_7_0.png"></center></p>

<p><div align="justify"><i>Ainda n√£o falamos do Boruta, mas ele se utiliza dessa ordena√ß√£o para fazer suas an√°lises e √© implementado, usualmente, utilizando medida de import√¢ncia do estimador (o atributo <code>.feature_importances_</code> ou <code>.coef_</code> para algoritmos lineares). Essa diferen√ßa motivou alguns contribuidores a implementar o <a href="https://github.com/Ekeany/Boruta-Shap">Boruta-Shap</a>. Entretanto, incorporar o SHAP ao processo do Boruta n√£o parece trivial e a biblioteca costuma ser lenta.</i></div></p>

<p><div align="justify"><i>Uma poss√≠vel alternativa pode ser adaptar na m√£o o atributo <code>.feature_importance_</code> do seu classificador, salvando o <code>X</code> no momento de treinamento para utiliza√ß√£o no c√°lculo do SHAP. Como implemento aqui:</i></div></p>

```python
class SHAPImportanceRandomForestClassifier(RandomForestClassifier):
    def fit(self, X, y, sample_weight=None):
        self.X_ = X
        super().fit(X, y, sample_weight=sample_weight)
        return self
    @property
    def feature_importances_(self):
        check_is_fitted(self)
        explainer = shap.TreeExplainer(self)
        shap_vals = explainer.shap_values(self.X_)
        return np.abs(shap_vals[0]).mean(axis=0)
```

```python
from shap_feature_importances_ import SHAPImportanceRandomForestClassifier

rfc_shap = SHAPImportanceRandomForestClassifier(random_state=42).fit(X, y)
rfc_shap.feature_importances_
```

    array([0.04156985, 0.19764501, 0.10721142, 0.04379691, 0.00509938,
           0.00967927, 0.00900892, 0.00769202, 0.01053711, 0.00973848,
           0.00764462, 0.00725161, 0.00690175, 0.00718789, 0.00600269,
           0.00526766, 0.00659648, 0.00585107, 0.00726538, 0.00501896])

<p><div align="justify"><i>Note que essa implementa√ß√£o utiliza o mesmo conjunto de treino para c√°lculo do SHAP. Existe algum debate aqui, mas tenha em mente que os valores de import√¢ncia calculados com SHAP (m√©dia do valor absoluto) no teste podem ser diferentes dos valores de import√¢ncia calculados com SHAP no treino. Se voc√™ quiser esse n√≠vel de preciosismo, pode estar interessado em reservar um peda√ßo do seu conjunto de dados para calcular os valores SHAP. Implemento essa ideia na classe <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/shap_feature_importances_.py"><code>XSHAPImportanceRandomForestClassifier</code></a> do arquivo <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/shap_feature_importances_.py"><code>shap_feature_importances_.py</code></a> no <a href="https://github.com/vitaliset/blog-notebooks/tree/main/DataLab_Blog_Boruta_2022_09_05">reposit√≥rio deste post</a>. Entretanto, para poder dormir tranquilo, tenha em mente que o <code>.feature_importances_</code> usual dos algoritmos baseados em √°rvore √© calculado com o conjunto de treino, ent√£o calcular o SHAP no treino n√£o √© uma blasf√™mia t√£o grande.</i></div></p>

## Selecionando as `K` "melhores vari√°veis"

<p><div align="justify">Se quisermos que nosso modelo tenha apenas as <code>K</code> features mais √∫teis, a maneira natural de escolher elas seria pegar as <code>K</code> vari√°veis com maiores valores de import√¢ncia.</div></p>

```python
K = 4

(df_imp
 .head(K)
 .feature_name
 .to_list()
)
```

    ['column_2', 'column_3', 'column_4', 'column_1']

<p><div align="justify">Essa √© uma das estrat√©gias mais comuns de se fazer sele√ß√£o de features no mercado, mas levanta algumas quest√µes. A primeira e mais imediata √©: como escolher o n√∫mero de vari√°veis <code>K</code> ideal. Nesse caso ilustrativo, sabemos que 4 vari√°veis √© o n√∫mero correto, mas na maioria dos casos de aplica√ß√£o real √© irrealista ter esse n√∫mero de antem√£o.</div></p>

<p><div align="justify"><i>$\oint$ Uma estrat√©gia muito utilizada, mas que n√£o vamos focar muito, √© aumentar a lista de features do modelo seguindo a ordena√ß√£o dada pelo modelo treinado em todas as features, encarando esse valor <code>K</code> como um hiper-par√¢metro que estamos otimizando. No exemplo abaixo, fazemos isso utilizando o <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"><code>sklearn.model_selection.GridSearchCV</code></a> ao construir uma classe <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/selectktop_selector.py"><code>SelectKTop</code></a> utilizando o padr√£o necess√°rio para os selecionadores de vari√°veis do scikit-learn, isto √©, seguindo a forma que o <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectorMixin.html"><code>sklearn.feature_selection.SelectorMixin</code></a> exige. Voc√™ pode ver a implementa√ß√£o dessa classe no arquivo <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/selectktop_selector.py"><code>selectktop_selector.py</code></a> no <a href="https://github.com/vitaliset/blog-notebooks/tree/main/DataLab_Blog_Boruta_2022_09_05">reposit√≥rio deste post</a>.</i></div></p>

<p><div align="justify"><i>PS: A classe <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/selectktop_selector.py"><code>SelectKTop</code></a> √© mais ou menos equivalente √† classe <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html"><code>sklearn.feature_selection.SelectFromModel</code></a>, cuja exist√™ncia descobri ap√≥s terminar de escrever o post!</i></div></p>

```python
from selectktop_selector import SelectKTop

from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold
from sklearn.pipeline import make_pipeline

grid = (
    GridSearchCV(
        make_pipeline(SelectKTop(random_state=42),
                      RandomForestClassifier(random_state=42)),
        param_grid={'selectktop__K': np.arange(1,N_FEATURES+1)},
        cv=RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42),
        scoring='roc_auc')
    .fit(X, y))

df_cv = (
    pd.DataFrame(grid.cv_results_)[[
        'param_selectktop__K',
        'mean_test_score',
        'std_test_score'
    ]])

cv_best = (
    df_cv
    .sort_values(by='mean_test_score', ascending=False)
    .reset_index(drop=True)
    .loc[0])
```

```python
plt.errorbar(df_cv.param_selectktop__K, df_cv.mean_test_score, 1.96*df_cv.std_test_score)
plt.scatter(cv_best.param_selectktop__K, cv_best.mean_test_score, s=100)
plt.ylim(0.75, 1)
plt.xlabel('K of SelectKTop')
plt.xticks(df_cv.param_selectktop__K.astype(int))
plt.ylabel('Performance (ROCAUC)')
plt.show()
```

<p><center><img src="{{ site.baseurl }}/assets/img/boruta/output_15_0.png"></center></p>

<p><div align="justify"><i>No nosso experimento controlado, encontramos algumas poucas vari√°veis a mais do que o correto (e ficamos com todas as √∫teis).</i></div></p>

```python
grid.best_estimator_.steps[0][1].get_feature_names_out()
```

    array(['column_1', 'column_2', 'column_3', 'column_4', 'column_10'],
          dtype=object)

<p><div align="justify"><i>Vale citar que podemos deixar esse m√©todo mais robusto variando o <code>random_state</code> do <code>base_estimator</code> e tendo uma distribui√ß√£o de import√¢ncias para cada vari√°vel ao inv√©s de apenas um valor √∫nico (que naturalmente √© mais ruidoso). Utilizar essa t√©cnica com o SHAP para medir a import√¢ncia (passando por exemplo o <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/shap_feature_importances_.py"><code>SHAPImportanceRandomForestClassifier</code></a> como <code>base_estimator</code> do <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/selectktop_selector.py"><code>SelectKTop</code></a>) √© algo muito utilizado por alguns cientistas do <a href="https://br.linkedin.com/showcase/serasa-experian-datalab">DataLab</a> como alternativa ao Boruta que, como vamos ver, costuma ser muito demorado.</i></div></p>

## Selecionando as K melhores vari√°veis com ponto de corte sugerido por uma vari√°vel aleat√≥ria

<p><div align="justify">Criar uma vari√°vel de ru√≠do, ou seja, que sabidamente n√£o √© √∫til para a previs√£o, nos auxilia a ter um ponto de corte para filtro das vari√°veis que demonstram ajudar na previs√£o. A ideia dessa abordagem √© medir a import√¢ncia da vari√°vel aleat√≥ria e ficar apenas com vari√°veis que se demonstrarem mais importantes do que ela.</div></p>

<p><div align="justify">Adicionando a nova coluna, por exemplo, amostrada de uma vari√°vel aleat√≥ria $\mathcal{N}(0,1)$ de forma independente, temos uma nova lista de import√¢ncia das vari√°veis.</div></p>

```python
normal_noise_X = (X.assign(noise_column = np.random.RandomState(42).normal(size=X.shape[0])))
normal_noise_X[normal_noise_X.columns[::-1]].head()
```

<p><center><img src="{{ site.baseurl }}/assets/img/boruta/output_20_0.png"></center></p>

```python
normal_noise_rfc = RandomForestClassifier(random_state=42).fit(normal_noise_X, y)

df_imp_normal_noise = \
(pd.DataFrame(list(zip(normal_noise_X.columns, normal_noise_rfc.feature_importances_)),
              columns=['feature_name', 'feature_importance'])
 .sort_values(by='feature_importance', ascending=False)
)

df_imp_normal_noise
```

<p><center><img src="{{ site.baseurl }}/assets/img/boruta/output_21_0.png"></center></p>

<p><div align="justify">Como a √∫ltima vari√°vel √© a nossa coluna sabidamente ruidosa, a ideia dessa t√©cnica √© selecionar apenas as vari√°veis que t√™m import√¢ncia maior do que o limiar definido pela import√¢ncia da vari√°vel n√£o relacionada.</div></p>

```python
normal_noise_importance = \
normal_noise_rfc.feature_importances_[-1]

np.array(
 df_imp_normal_noise
 .query(f"feature_importance > {normal_noise_importance}")
 .feature_name
)
```

    array(['column_2', 'column_3', 'column_4', 'column_1', 'column_6',
           'column_10', 'column_14'], dtype=object)

<p><div align="justify">Vale observar que, a escolha da vari√°vel ruidosa como $\mathcal{N}(0,1)$ foi totalmente arbitr√°ria. Entretanto, isso faz diferen√ßa e pode fazer com que a sele√ß√£o de vari√°veis seja distinta. No nosso exemplo controlado, mudar o ru√≠do para $\textrm{Exp}(1)$ nos faria selecionar vari√°veis finais diferentes totalmente por sorte.</div></p>

```python
exp_noise_X = \
(X.assign(noise_column = np.random.RandomState(42).exponential(size=X.shape[0])))
exp_noise_rfc = \
RandomForestClassifier(random_state=0).fit(exp_noise_X, y)
exp_noise_importance = \
exp_noise_rfc.feature_importances_[-1]

np.array(
 pd.DataFrame(list(zip(exp_noise_X.columns, exp_noise_rfc.feature_importances_)),
              columns=['feature_name', 'feature_importance'])
 .sort_values(by='feature_importance', ascending=False)
 .query(f"feature_importance > {exp_noise_importance}")
 .feature_name
)
```

    array(['column_2', 'column_3', 'column_4', 'column_1', 'column_14',
           'column_6', 'column_10', 'column_9', 'column_12', 'column_13',
           'column_7', 'column_18'], dtype=object)

<p><div align="justify">Isso nos demonstra um problema desse m√©todo. Apesar de poderoso, por nos dar um jeito interessante de selecionar as vari√°veis sem escolher <code>K</code> de forma arbitr√°ria, a escolha da distribui√ß√£o da vari√°vel ruidosa √© uma fonte de varia√ß√£o relevante.</div></p>

<p><div align="justify">Em muitos casos, ter vari√°veis discretas versus cont√≠nuas pode influenciar na medida de import√¢ncia (como √© o caso de √°rvores que, por terem mais quebras dispon√≠veis, ter√£o mais chance de escolher uma vari√°vel ruidosa cont√≠nua) ou, ainda, a pr√≥pria escala da feature adicionada pode atrapalhar nessa mensura√ß√£o (por exemplo, se estamos usando os coeficientes angulares de um <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"><code>sklearn.linear_model.Lasso</code></a>).</div></p>

<p><div align="justify">Toda essa variabilidade pode fazer com que, as vezes, uma feature ruim seja selecionada, ao passo que uma vari√°vel boa seja descartada por azar.</div></p>

<p><div align="justify">O Boruta vem para tentar lidar com essas duas quest√µes ao mesmo tempo: tentar manter a distribui√ß√£o marginal das features ruidosas iguais √†s distribui√ß√µes marginais das features originais, enquanto tenta ser robusto √† variabilidade, repetindo o experimento algumas vezes.</div></p>

# Ideias gerais do Boruta

<p><div align="justify">J√° existem muitos textos √∫teis que explicam o Boruta de forma did√°tica e com exemplos. Como a ideia desse post n√£o √© ser redundante com a literatura e sim compilar ideias centrais de uso pr√°tico, vamos apenas citar os principais aspectos e deixar o convite para uma leitura detalhada de outras refer√™ncias do tema como o post <a href="https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a">Boruta Explained Exactly How You Wished Someone Explained to You</a>. A constru√ß√£o que fizemos anteriormente vai deixar as ideias do Boruta ainda mais claras, justificando o seu modo de ser.</div></p>

<p><div align="justify">Em resumo, o Boruta [<a href="#bibliography">2,4</a>]:</div></p>
- <p><div align="justify">Cria vari√°veis n√£o correlacionadas com a <em>target</em> ao embaralhar, entre as linhas, vari√°veis j√° presentes no dataset (essas s√£o as vari√°veis que chamamos de <em>shadow</em>).</div></p>
- <p><div align="justify">Lida com a variabilidade repetindo o processo v√°rias vezes e marcando quantas vezes a nossa vari√°vel de interesse ficou atr√°s do percentil <code>perc</code> dos <code>.feature_importances</code> das <em>shadow features</em> (por default <code>perc=100</code>, portanto, comparamos com o m√°ximo dos <code>.feature_importances</code> das <em>shadow features</em>, isto √©, se alguma <em>shadow</em> for melhor, j√° descartamos aquela vari√°vel de interesse naquela rodada).</div></p>
- <p><div align="justify">Por fim, um teste de hip√≥tese √© feito para avaliar se podemos afirmar com alguma signific√¢ncia estat√≠stica <code>alpha</code> que a feature de interesse √© melhor que o percentil <code>perc</code> da import√¢ncia das <em>shadow features</em>.</div></p>
- <p><div align="justify">O teste de hip√≥tese divide o conjunto de features em tr√™s categorias:</div></p>
    - <p><div align="justify">As vari√°veis que estatisticamente s√£o vari√°veis melhores que as <em>shadow features</em> (s√£o as chamadas de <code>.support_</code>);</div></p>
    - <p><div align="justify">As vari√°veis que estatisticamente s√£o equivalentes √†s vari√°veis <em>shadow</em> (vari√°veis que exclu√≠mos);</div></p>
    - <p><div align="justify">As vari√°veis que n√£o s√£o poss√≠veis de afirmar com signific√¢ncia estat√≠stica como sendo melhores que as vari√°veis <em>shadow</em> (<code>.weak_support_</code>).</div></p>
- <p><div align="justify">Na pr√°tica, a partir do momento que ele tem confian√ßa de que uma determinada vari√°vel n√£o √© importante, ele j√° a exclui das pr√≥ximas itera√ß√µes.</div></p>


# O [boruta.BorutaPy](https://github.com/scikit-learn-contrib/boruta_py)

<p><div align="justify">Primeiro, precisamos instanciar um <code>base_estimator</code> que ser√° utilizado dentro do <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> para calcular a import√¢ncia das vari√°veis (atrav√©s do <code>.feature_importances_</code> ou do <code>.coef_</code>). √â importante ressaltar que podemos adicionar hiper-par√¢metros que acharmos relevantes para o problema, como o <code>class_weight</code> se temos um problema muito desbalanceado.</div></p>

<p><div align="justify">Quando usamos um c√¥mite de √°rvores, √© importante ter em mente que √°rvores profundas v√£o mudar o <code>.feature_importances_</code>, mas v√£o demorar mais para treinar. √â justific√°vel utilizar √°rvores mais rasas, uma vez que os ganhos mais expressivos s√£o feitos nas primeiras quebras, usualmente.</div></p>

<p><div align="justify">O <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> aceita qualquer estimador que tenha o atributo <code>.feature_importances_</code> dispon√≠vel ap√≥s rodar o m√©todo <code>.fit(X, y)</code> [<a href="#bibliography">5</a>]. Voc√™ pode utilizar isso a seu favor usando os estimadores mais adequados para o seu problema, inclusive, utilizando algoritmos baseados em √°rvores mais eficientes como as <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"><code>sklearn.ensemble.ExtraTreesClassifier</code></a> (tenha em mente que as Extra Randomized Trees v√£o ter seu <code>.feature_importances_</code> afetado pelo m√©todo de constru√ß√£o e isso pode impactar a escolha final de vari√°veis).</div></p>

<p><div align="justify">Para exemplificar a utiliza√ß√£o pr√°tica da biblioteca, vou utilizar o <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/shap_feature_importances_.py"><code>SHAPImportanceRandomForestClassifier</code></a> que criamos anteriormente (basicamente um <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"><code>sklearn.ensemble.RandomForestClassifier</code></a> com SHAP no lugar do <code>.feature_importances_</code> usual).</div></p>


```python
from boruta import BorutaPy

boruta_forest = SHAPImportanceRandomForestClassifier(max_depth=7, random_state=42)
```

<p><div align="justify">Um ponto de aten√ß√£o que n√£o √© necessariamente claro na documenta√ß√£o, √© que o par√¢metro <code>n_estimators</code> do <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> sobrescreve o <code>n_estimators</code> do estimador como podemos ver no <a href="https://github.com/scikit-learn-contrib/boruta_py/blob/3cf4de864e83ad0c50e0cfa177b2bc2aa4735256/boruta/boruta_py.py#L268">c√≥digo fonte do BorutaPy</a>:</div></p>

```python
# set n_estimators
if self.n_estimators != 'auto':
    self.estimator.set_params(n_estimators=self.n_estimators)
```
<p><div align="justify">Por default, temos <code>n_estimators=1000</code>. Se <code>n_estimators=&#39;auto&#39;</code>, ent√£o <a href="https://github.com/scikit-learn-contrib/boruta_py/blob/3cf4de864e83ad0c50e0cfa177b2bc2aa4735256/boruta/boruta_py.py#L371">uma regra baseada no n√∫mero de features que estamos avaliando √© feita para escolher o n√∫mero de √°rvores do ensemble</a>.</div></p>

<p><div align="justify">Por fim, <code>alpha</code> e <code>perc</code> s√£o os outros par√¢metros importantes do <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> que voc√™ deveria ficar atento:</div></p>
- <p><div align="justify">O <code>perc</code> (percentil do <code>.feature_importances_</code> das <em>shadow features</em> utilizado para decidir se as vari√°veis foram boas ou n√£o naquela determinada rodada) √© um <code>int</code> que vai de 0 a 100. Quanto mais pr√≥ximo de 100, mais rigoroso estamos sendo na hora de avaliar nossas features. Pela aleatoriedade, alguns <code>.feature_importances_</code> de <em>shadow features</em> podem ser grandes e muito rigorosos com o crit√©rio de corte, nesse caso, isso ser√° ruim porque estaremos excluindo vari√°veis marginais que s√£o relevantes, mas n√£o t√™m uma import√¢ncia t√£o expressiva. O default desse par√¢metro √© 100, mas recomendo abaix√°-lo levemente (para 90, por exemplo) caso esteja trabalhando com um problema com muitas vari√°veis, desse modo haver√° maior chance de se ter uma <em>shadow feature</em> com import√¢ncia alta.</div></p>
- <p><div align="justify">O <code>alpha</code> √© um float que vai de 0 a 1 e √© importante para delimitar a parti√ß√£o que fazemos do conjunto de vari√°veis (<code>.support_weak_</code>, <code>.support</code> e exclu√≠das), uma vez que determinar√° o rigor de certeza que queremos ter para afirmar que uma determinada feature √© relevante ou n√£o para o problema de classifica√ß√£o (ou regress√£o). O default desse par√¢metro √© 0.05, e eu n√£o tenho o costume de alter√°-lo, pois prefiro mant√™-lo fixo e variar o <code>perc</code> j√° que os dois se relacionam.</div></p>

```python
boruta = \
(BorutaPy(
    estimator=boruta_forest,
    n_estimators=50,
    max_iter=100, # number of trials to perform
    random_state=42)
 .fit(np.array(X), np.array(y)) # fit accepts np.array, not pd.DataFrame
)
```

<p><div align="justify">Por fim, √© f√°cil resgatar as features com os atributos <code>.support_</code> e <code>.support_weak_</code>.</div></p>

```python
green_area = X.columns[boruta.support_].to_list()
blue_area = X.columns[boruta.support_weak_].to_list()

print('Support columns:', green_area)
print('Weak support columns:', blue_area)
```

    Support columns: ['column_1', 'column_2', 'column_3', 'column_4', 'column_10']
    Weak support columns: ['column_9']

# Trade-off de "qualidade da sele√ß√£o" vs "tempo" quando damos um undersample

<p><div align="justify">Quando temos um dataset muito grande, o <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> pode demorar bastante tempo para rodar pelo processo de criar tantas vari√°veis <em>shadows</em> quanto temos no conjunto inicial de vari√°veis. Em muitas aplica√ß√µes pr√°ticas √© necess√°rio aplicar o <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> em um subconjunto do seu conjunto de treinamento.</div></p>

<p><div align="justify">Faremos aqui um experimento para ver, em um caso sint√©tico de <code>make_classification</code> com <code>n_samples=5000</code>, <code>n_features=100</code>, <code>n_informative=40</code> e <code>n_redundant=10</code>, como seriam as escolhas de vari√°veis de um <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> conforme variamos o par√¢metro <code>frac</code> de um <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html"><code>.sample</code></a> feito na base de desenvolvimento.</div></p>

```python
from boruta_sample_experiment import experiment, plot_heatmap, plot_percentage_time

dic_sample, matrix, X_big, y_big = \
experiment(fracs=[0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])
```
    100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11/11 [14:08<00:00, 77.18s/it]

<p><div align="justify">Como o n√∫mero de vari√°veis informativas mais o n√∫mero de vari√°veis redundantes √© 50 ent√£o, nesse exemplo controlado, metade das nossas features s√£o importantes. No plot abaixo, para diferentes valores de <code>frac</code> (fra√ß√£o dos exemplos da base usado para treinar o <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a>) vemos quais vari√°veis est√£o sendo escolhidas. Idealmente, o <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> deveria conseguir identificar que as primeiras 50 vari√°veis (eixo x) s√£o as √∫teis e selecion√°-las (pintando-as de verde), enquanto exclui as 50 demais (pintando-as de azul), haja vista que s√£o ru√≠do. Conforme variamos o <code>frac</code> (eixo y), vemos como ele se comporta.</div></p>

```python
plot_heatmap(dic_sample, matrix)
```

<p><center><img src="{{ site.baseurl }}/assets/img/boruta/output_38_0.png"></center></p>

<p><div align="justify">Na primeira figura abaixo, vemos uma sumariza√ß√£o do plot anterior variando o <code>frac</code> (eixo x), enquanto observamos a porcentagem das vari√°veis √∫teis (em verde) e in√∫teis (em laranja) que s√£o escolhidas. No gr√°fico ao lado, h√° uma an√°lise de tempo (de treinamento do <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a>) e performance do modelo treinado com as vari√°veis escolhidas naquele valor de <code>frac</code>.</div></p>

```python
plot_percentage_time(dic_sample, matrix, X_big, y_big)
```

<p><center><img src="{{ site.baseurl }}/assets/img/boruta/output_40_0.png"></center></p>

<p><div align="justify">Como podemos ver, n√£o precisamos de todas as amostras para treinar o nosso <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a>. No exemplo anterior, apesar da nossa amostra ter 5000 elementos, com algo em torno de 3000 exemplos, j√° era poss√≠vel encontrar perfeitamente todas as 50 vari√°veis √∫teis para o nosso problema.</div></p>

<p><div align="justify">Na minha experi√™ncia utilizando o <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a>, me sinto confort√°vel com _uma amostra com 15 vezes mais exemplos do que features (ou seja, <code>n_samples&gt;=15*n_features</code>)_. Nesse limiar, j√° costumo ter resultados bons em termos de sele√ß√£o de vari√°veis e √© poss√≠vel rodar o algoritmo (em tempo satisfat√≥rio para desenvolvimento) com um <code>max_depth</code> controlado. Colocando um exemplo num√©rico: se, no <a href="https://br.linkedin.com/showcase/serasa-experian-datalab">DataLab</a>, estou trabalhando com um problema de 5 mil vari√°veis, me sinto confort√°vel em rodar o <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> em uma amostra de 75 mil linhas, mesmo tendo muito mais exemplos na base de desenvolvimento.</div></p>

<p><div align="justify">Por outro lado, o exemplo anterior nos mostra que nem sempre isso √© o melhor, mesmo em quest√£o de tempo. O <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a>, na pr√°tica, n√£o vai rodar por <code>max_iter</code> se j√° tiver certeza (no n√≠vel de signific√¢ncia <code>alpha</code>) das vari√°veis que ele acha √∫teis para o problema, que ele j√° exclui (ou seleciona) no meio do caminho. No experimento anterior, ter mais exemplos, na verdade, fez com que o <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> ficasse com mais certeza de forma mais r√°pida sobre as vari√°veis. Na pr√°tica, isso dificilmente acontece.</div></p>

# Usando o Boruta na pr√°tica e algumas alternativas

<p><div align="justify">As ideias por tr√°s do <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> s√£o muito interessantes, mas o algoritmo final √© temporalmente custoso. Por sorte, podemos utilizar as ideias da constru√ß√£o para fazer varia√ß√µes espertas que podem ser alternativas se uma rodada inicial (com <code>max_depth ~ 10</code>, <code>perc=90</code> e <code>n_estimators=500</code>) estiver demorando demais:</div></p>
1. <p><div align="justify">Utilizar o <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/selectktop_selector.py"><code>SelectKTop</code></a> com alguma m√©trica de <code>.feature_importances_</code> mais robusta (como o SHAP, usando algo como nosso <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/shap_feature_importances_.py"><code>SHAPImportanceRandomForestClassifier</code></a>) e tendo cuidado com a escolha do <code>K</code>;</div></p>
2. <p><div align="justify">Adaptar o <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/selectktop_selector.py"><code>SelectKTop</code></a> que constru√≠mos para um vers√£o ainda mais robusta que lida com uma distribui√ß√£o de <code>.feature_importances_</code> ao inv√©s de apenas um estimador (ali√°s, esse √© um √≥timo exerc√≠cio para o leitor interessado em entender melhor a <a href="https://scikit-learn.org/stable/developers/develop.html">API do scikit-learn</a>);</div></p>
3. <p><div align="justify">Adaptar o <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/selectktop_selector.py"><code>SelectKTop</code></a> para um &quot;<code>SelectAboveNoise</code>&quot;, que explicamos anteriormente, criando as vari√°veis aleat√≥rias a partir do <a href="https://numpy.org/doc/stable/reference/random/index.html"><code>numpy.random</code></a> (outro exerc√≠cio muito bom);</div></p>
4. <p><div align="justify">Utilizar o <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> com algoritmos mais r√°pidos (como <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"><code>sklearn.ensemble.ExtraTreesClassifier</code></a>), mas lembrando que seu treinamento (ainda mais randomizado) vai afetar o <code>.feature_importances_</code> e, consequentemente, o resultado final.</div></p>
5. <p><div align="justify">Reduzir a amostra utilizada para treino do <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> respeitando a <em>rule of thumb</em> de <code>n_samples&gt;=15*n_features</code>.</div></p>
6. <p><div align="justify">Mexer mais estruturalmente no algoritmo de forma que ele crie menos vari√°veis <em>shadows</em> em problemas com muitas vari√°veis (<em>to be tested</em>).</div></p>

<p><div align="justify">Se o seu problema √© razoavelmente pequeno, usar o <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> com o SHAP e otimizar os hiper-par√¢metros do <a href="https://github.com/scikit-learn-contrib/boruta_py"><code>boruta.BorutaPy</code></a> √© uma boa op√ß√£o. Para isso, ser√° √∫til utilizar o <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/boruta_selector.py"><code>Boruta</code></a> que criei no arquivo <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/boruta_selector.py"><code>boruta_selector.py</code></a> no <a href="https://github.com/vitaliset/blog-notebooks/tree/main/DataLab_Blog_Boruta_2022_09_05">reposit√≥rio deste post</a>. Ele j√° est√° no formato adequado de <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectorMixin.html"><code>Selector</code></a> do scikit-learn e pode ser utilizado da mesma forma que vimos o <a href="https://github.com/vitaliset/blog-notebooks/blob/main/DataLab_Blog_Boruta_2022_09_05/selectktop_selector.py"><code>SelectKTop</code></a> sendo usado (com um pipeline e qualquer <a href="https://github.com/scikit-learn/scikit-learn/blob/36958fb240fbe435673a9e3c52e769f01f36bec0/sklearn/model_selection/_search.py#L372"><code>BaseSearchCV</code></a> do scikit-learn).</div></p>

# Conclus√£o

<p><div align="justify">Sele√ß√£o de vari√°veis √© um assunto necess√°rio quando queremos garantir ter um modelo robusto. Neste post vimos uma das t√©cnicas mais √∫teis para abordar esse problema enquanto, ao entender suas ideias, discutimos como adapt√°-la para uma variedade de casos espec√≠ficos. Mesmo que voc√™ n√£o consiga usar o Boruta no seu problema em quest√£o, as ideias aqui expostas permitem que voc√™ fa√ßa uma sele√ß√£o de vari√°veis sabendo melhor as falhas e os benef√≠cios de abordagens usuais do mercado.</div></p>


# <a name="bibliography">Refer√™ncias</a>

<p><div align="justify">[1] <a href="https://cs.nyu.edu/~mohri/mlbook/">Foundations of Machine Learning. Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. MIT Press, Second Edition, 2018</a>.</div></p>

<p><div align="justify">[2] <a href="https://www.jstatsoft.org/article/view/v036i11">Feature Selection with the Boruta Package. Miron B. Kursa, Witold R. Rudnicki. Journal of Statistical Software</a>.</div></p>

<p><div align="justify">[3] <a href="https://youtu.be/_L39rN6gz7Y">Decision and Classification Trees, Clearly Explained!!!. Josh Starmer. StatQuest with Josh Starmer</a>.</div></p>

<p><div align="justify">[4] <a href="https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a">Boruta Explained Exactly How You Wished Someone Explained to You. Samuele Mazzanti. Towards Data Science</a>.</div></p>

<p><div align="justify">[5] <a href="https://github.com/scikit-learn-contrib/boruta_py">boruta_py README.md documentation. Daniel Homola</a>.</div></p>

<p><div align="justify">Para mais dicas pr√°ticas de uso (e com um argumento de autoridade muito melhor que o meu), o autor do Boruta tem o guia <a href="https://cran.r-project.org/web/packages/Boruta/vignettes/inahurry.pdf">Boruta for those in a hurry</a> que, apesar de estar escrito em R, tem dicas pr√°ticas interessantes de algu√©m que conhece a implementa√ß√£o com muita profundidade.</div></p>

___

<p><div align="justify">Todos os arquivos e ambiente para reprodu√ß√£o dos experimentos podem ser encontrado no <a href="https://github.com/vitaliset/blog-notebooks/tree/main/DataLab_Blog_Boruta_2022_09_05">reposit√≥rio deste post</a>.</div></p>

<p><div align="justify">Este post foi originalmente publicado no <a href="https://medium.com/datalab-log">Medium do Experian DataLab</a>! Passe no <a href="https://medium.com/datalab-log/sele%C3%A7%C3%A3o-de-vari%C3%A1veis-uma-utiliza%C3%A7%C3%A3o-cr%C3%ADtica-do-boruta-f3e974238f56">post</a> e deixe uma palminha, se achar que faz sentido! :D</div></p>
